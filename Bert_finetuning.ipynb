{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_finetuning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMNG2aDutE45r4nrFslSk9z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqXc6NYwQno0"
      },
      "source": [
        "# Preliminaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjBsjOepupvb"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaccpgM3CgFY"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import os\n",
        "import ast\n",
        "\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVeoVKGxusJC"
      },
      "source": [
        "## Device configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5tZJVdBCnzC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef9658fa-9e48-4f37-8991-798b35383c22"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bPFJcIxuvd-"
      },
      "source": [
        "## Conect to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCljQXoCo3WU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0876f4-12e1-4c81-c9ed-9f023c6d3f54"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jxHlncVo5K4"
      },
      "source": [
        "source_folder = '/content/drive/MyDrive/data_rakuten' #source folder of csv files"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4KQymK3uzyh"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHDmUq-0pLRw"
      },
      "source": [
        "#Load data\n",
        "\n",
        "XTrain = pd.read_csv(os.path.join(source_folder,'X_train_12tkObq.csv'), index_col=0)\n",
        "XTest = pd.read_csv(os.path.join(source_folder,'X_test_gDTIJPh.csv'), index_col=0)\n",
        "\n",
        "Ytrain_label = torch.load('/content/drive/MyDrive/data_rakuten/Ytrain_label.pt')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yrXk0-Ou3nP"
      },
      "source": [
        "## Create dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoRd02tGpQOH"
      },
      "source": [
        "class TextDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "      #Load pre-computed tensors\n",
        "      self.text_name = XTrain['item_name']\n",
        "     # self.text_caption = XTrain['item_caption']\n",
        "      self.tokenizer = BertTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-v2')\n",
        "      self.labels = Ytrain_label\n",
        "        #torch.cat((Xtrain_item_name,Xtrain_item_caption),0)\n",
        "    def __len__(self):\n",
        "        return len(self.text_name)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokenized_text_name    = self.tokenizer.tokenize(self.text_name[idx])\n",
        "    #    tokenized_text_caption = self.tokenizer.tokenize(str(self.text_caption[idx])) #sometimes there is no caption so str() is required\n",
        "\n",
        "        indexed_tokens_name    = self.tokenizer.convert_tokens_to_ids(tokenized_text_name)\n",
        "      #  indexed_tokens_caption = self.tokenizer.convert_tokens_to_ids(tokenized_text_caption)\n",
        "        \n",
        "        tokens_tensor_name     = torch.tensor([indexed_tokens_name])\n",
        "       # tokens_tensor_caption  = torch.tensor([indexed_tokens_caption])\n",
        "\n",
        "        tokens_tensor_name    = tokens_tensor_name[0,:100] #to prevent tokens sequence longer than 512 tokens\n",
        "      #  tokens_tensor_caption = tokens_tensor_caption[0,:412] #to prevent tokens sequence longer than 512 tokens\n",
        "\n",
        "        #return  torch.cat((tokens_tensor_name,tokens_tensor_caption),0),self.labels[:,idx]\n",
        "        return  tokens_tensor_name,self.labels[:,idx]\n",
        "\n",
        "def generate_batch(data_batch):\n",
        "  tokens_batch = [item[0] for item in data_batch]\n",
        "  labels_batch = [item[1] for item in data_batch]\n",
        "  tokens_batch = pad_sequence(tokens_batch,batch_first=True, padding_value=1)\n",
        "  labels_batch = pad_sequence(labels_batch,batch_first=True, padding_value=0) #just to have tensor instead of list\n",
        "  \n",
        "  return tokens_batch, labels_batch\n",
        "\n",
        "trainSet= TextDataset()\n",
        "trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=64,shuffle=True, collate_fn=generate_batch)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTyHouu2pNRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cfed017-e1d7-4e3e-b8a9-c88a53f05fd6"
      },
      "source": [
        "class CustomModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "\n",
        "        \n",
        "        self.encoder   =  BertModel.from_pretrained('cl-tohoku/bert-base-japanese-v2')\n",
        "        for param in self.encoder.parameters(): \n",
        "                param.requires_grad = False\n",
        "        self.fc1 = torch.nn.Linear(768, 450)\n",
        "        self.fc2 = torch.nn.Linear(450, 200)\n",
        "        self.fc3 = torch.nn.Linear(200, 19)\n",
        "\n",
        "\n",
        "    def forward(self, tokens_tensor):\n",
        "        text_features  = self.encoder.forward(input_ids=tokens_tensor,return_dict=True)\n",
        "        text_features  = text_features['pooler_output'].squeeze(0)\n",
        "        text_features = F.relu(self.fc1(text_features))\n",
        "        text_features = F.relu(self.fc2(text_features))\n",
        "        logits = self.fc3(text_features)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def relaxation(self,type_relax):\n",
        "        if type_relax==\"soft\":\n",
        "            for name,param in self.named_parameters():\n",
        "                if name.startswith('encoder.encoder.layer.11') or name.startswith('encoder.pooler.dense'):\n",
        "                    param.requires_grad = True\n",
        "        elif type_relax==\"hard\":\n",
        "            for param in self.encoder.parameters(): \n",
        "                param.requires_grad = True\n",
        "    \n",
        "\n",
        "model=CustomModel()\n",
        "model.relaxation('soft')\n",
        "model.to(device)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomModel(\n",
              "  (encoder): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32768, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (fc1): Linear(in_features=768, out_features=450, bias=True)\n",
              "  (fc2): Linear(in_features=450, out_features=200, bias=True)\n",
              "  (fc3): Linear(in_features=200, out_features=19, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4El24kbxP7D3"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHOITL3-P8hx"
      },
      "source": [
        "nbr_labels_positive = torch.tensor([25673,71831,34014,33338,2383,8303,21697,28814,8353,12597,25017,10378,24582,10355,23583,12911,3325,51751,14534]) #number of labels\n",
        "nbr_labels_negative = nbr_labels_positive.sum()*torch.ones(19)-nbr_labels_positive\n",
        "coeffs = nbr_labels_negative/nbr_labels_positive    #coefficients for each label\n",
        "coeffs = coeffs.to(device)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mLlR45aP__K"
      },
      "source": [
        "criterion = torch.nn.BCEWithLogitsLoss()#pos_weight=coeffs)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.7)\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainLoader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        if batch_idx%100==0:\n",
        "            print('{:.0f}%|Train Loss: {:.5f} '.format(100*batch_idx/(len(trainLoader)+1),train_loss/(batch_idx+1)))\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnbZj7cfSJQ0",
        "outputId": "435f871d-4b0e-4228-96c4-0e0537e484dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# training loop\n",
        "for epoch in range(100):\n",
        "    train(epoch)\n",
        "    scheduler.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            "0%|Train Loss: 0.70422 \n",
            "3%|Train Loss: 0.33453 \n",
            "6%|Train Loss: 0.32090 \n",
            "9%|Train Loss: 0.31308 \n",
            "12%|Train Loss: 0.31142 \n",
            "15%|Train Loss: 0.30896 \n",
            "18%|Train Loss: 0.30770 \n",
            "21%|Train Loss: 0.30621 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BQK7HVrYq0xs",
        "outputId": "15a96ae7-a93b-4fe8-fad9-7598799b0a38"
      },
      "source": [
        "# training loop\n",
        "for epoch in range(100):\n",
        "    train(epoch)\n",
        "    scheduler.step()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            "0%|Train Loss: 0.69838 \n",
            "3%|Train Loss: 0.32401 \n",
            "6%|Train Loss: 0.31578 \n",
            "9%|Train Loss: 0.31148 \n",
            "12%|Train Loss: 0.30887 \n",
            "15%|Train Loss: 0.30719 \n",
            "18%|Train Loss: 0.30627 \n",
            "21%|Train Loss: 0.30568 \n",
            "24%|Train Loss: 0.30498 \n",
            "27%|Train Loss: 0.30414 \n",
            "30%|Train Loss: 0.30356 \n",
            "33%|Train Loss: 0.30269 \n",
            "36%|Train Loss: 0.30240 \n",
            "39%|Train Loss: 0.30208 \n",
            "42%|Train Loss: 0.30182 \n",
            "45%|Train Loss: 0.30184 \n",
            "48%|Train Loss: 0.30135 \n",
            "51%|Train Loss: 0.30060 \n",
            "54%|Train Loss: 0.30038 \n",
            "57%|Train Loss: 0.30017 \n",
            "60%|Train Loss: 0.29981 \n",
            "63%|Train Loss: 0.29941 \n",
            "66%|Train Loss: 0.29896 \n",
            "69%|Train Loss: 0.29863 \n",
            "72%|Train Loss: 0.29832 \n",
            "75%|Train Loss: 0.29798 \n",
            "78%|Train Loss: 0.29766 \n",
            "81%|Train Loss: 0.29720 \n",
            "84%|Train Loss: 0.29702 \n",
            "87%|Train Loss: 0.29672 \n",
            "90%|Train Loss: 0.29638 \n",
            "93%|Train Loss: 0.29611 \n",
            "97%|Train Loss: 0.29583 \n",
            "100%|Train Loss: 0.29545 \n",
            "\n",
            "Epoch: 1\n",
            "0%|Train Loss: 0.30309 \n",
            "3%|Train Loss: 0.28496 \n",
            "6%|Train Loss: 0.28492 \n",
            "9%|Train Loss: 0.28479 \n",
            "12%|Train Loss: 0.28410 \n",
            "15%|Train Loss: 0.28380 \n",
            "18%|Train Loss: 0.28334 \n",
            "21%|Train Loss: 0.28284 \n",
            "24%|Train Loss: 0.28262 \n",
            "27%|Train Loss: 0.28223 \n",
            "30%|Train Loss: 0.28181 \n",
            "33%|Train Loss: 0.28145 \n",
            "36%|Train Loss: 0.28079 \n",
            "39%|Train Loss: 0.28058 \n",
            "42%|Train Loss: 0.27991 \n",
            "45%|Train Loss: 0.27946 \n",
            "48%|Train Loss: 0.27913 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-cfd2c4d7a85d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-1e78347e90f9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2Dtdj7_QERa"
      },
      "source": [
        "#Save weights\n",
        "model_file = \"/content/drive/MyDrive/data_rakuten/textmodelFinetune.pth\"\n",
        "torch.save(model.state_dict(), model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMMQBTLEQIey"
      },
      "source": [
        "#Load weights\n",
        "model_file = \"/content/drive/MyDrive/data_rakuten/textmodelFinetune.pth\"\n",
        "state_dict = torch.load(model_file)\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_gpsdBZQQSy"
      },
      "source": [
        "## Generate csv file for submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTFJssujQTmi"
      },
      "source": [
        "class TestDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self,):\n",
        "\n",
        "        self.features = XTest[\"item_caption\"]\n",
        "        \n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.features.shape[1]\n",
        "\n",
        "\n",
        "    #all this processing needs to be done here because the output of __getitem__ needs to have a fixed size to use a BS>1\n",
        "    def __getitem__(self, idx):\n",
        " \n",
        "        return  self.features[:,idx]\n",
        "\n",
        "testSet= TestDataset()\n",
        "testLoader = torch.utils.data.DataLoader(testSet, batch_size=1,shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvAZ9dfXQVVg"
      },
      "source": [
        "inv_dico_labels={ 0: \"Beige\",1:\"Black\",2:\"Blue\",3:\"Brown\",4:\"Burgundy\",5:\"Gold\",6:\"Green\",7:\"Grey\",\n",
        "                 8:\"Khaki\",9:\"Multiple Colors\",10:\"Navy\",11:\"Orange\",12:\"Pink\",\n",
        "                 13:\"Purple\",14:\"Red\",15:\"Silver\",16:\"Transparent\",17:\"White\",18:\"Yellow\"}\n",
        "\n",
        "model.eval()\n",
        "\n",
        "#Write prediction in the submission.csv file\n",
        "\n",
        "with open('/content/drive/MyDrive/data_rakuten/submission.csv', 'w') as csvfile:\n",
        "    spamwriter = csv.writer(csvfile, delimiter=',')\n",
        "    spamwriter.writerow([',color_tags,'])\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, inputs in enumerate(testLoader):\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            prediction=[]\n",
        "            for indice,logits in enumerate(outputs.squeeze(0)):\n",
        "                if logits>0: #put the tag if the proba is greater than 0.5\n",
        "                    prediction.append(inv_dico_labels[indice]) \n",
        "            \n",
        "            if len(prediction)>1:\n",
        "                spamwriter.writerow(['{},\"{}\"'.format(batch_idx,prediction)])\n",
        "            else:\n",
        "                spamwriter.writerow(['{},{}'.format(batch_idx,prediction)])\n",
        "            if batch_idx>300:\n",
        "              break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}