{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_finetuning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOwX9IJoOBA5h7ovHI16ZLf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqXc6NYwQno0"
      },
      "source": [
        "# Preliminaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjBsjOepupvb"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaccpgM3CgFY"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import ast\n",
        "\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVeoVKGxusJC"
      },
      "source": [
        "## Device configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5tZJVdBCnzC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "833eb3af-c39f-47dd-c277-d8fd82617c39"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bPFJcIxuvd-"
      },
      "source": [
        "## Conect to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCljQXoCo3WU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f984586-82a8-4735-a6ad-4050b9c64324"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jxHlncVo5K4"
      },
      "source": [
        "source_folder = '/content/drive/MyDrive/data_rakuten' #source folder of csv files"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4KQymK3uzyh"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHDmUq-0pLRw"
      },
      "source": [
        "#Load data\n",
        "\n",
        "XTrain = pd.read_csv(os.path.join(source_folder,'X_train_12tkObq.csv'), index_col=0)\n",
        "XTest = pd.read_csv(os.path.join(source_folder,'X_test_gDTIJPh.csv'), index_col=0)\n",
        "\n",
        "Ytrain_label = torch.load('/content/drive/MyDrive/data_rakuten/Ytrain_label.pt')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yrXk0-Ou3nP"
      },
      "source": [
        "## Create dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoRd02tGpQOH"
      },
      "source": [
        "class TextDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "      #Load pre-computed tensors\n",
        "      self.text_name = XTrain['item_caption']\n",
        "     # self.text_caption = XTrain['item_caption']\n",
        "      self.tokenizer = BertTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-v2')\n",
        "      self.labels = Ytrain_label\n",
        "        #torch.cat((Xtrain_item_name,Xtrain_item_caption),0)\n",
        "    def __len__(self):\n",
        "        return len(self.text_name)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        if str(self.text_name[idx])=='nan':\n",
        "            tokenized_text_name=self.tokenizer.tokenize('何もない')\n",
        "        else:\n",
        "          tokenized_text_name    = self.tokenizer.tokenize(self.text_name[idx])\n",
        "    #    tokenized_text_caption = self.tokenizer.tokenize(str(self.text_caption[idx])) #sometimes there is no caption so str() is required\n",
        "\n",
        "        indexed_tokens_name    = self.tokenizer.convert_tokens_to_ids(tokenized_text_name)\n",
        "      #  indexed_tokens_caption = self.tokenizer.convert_tokens_to_ids(tokenized_text_caption)\n",
        "        \n",
        "        tokens_tensor_name     = torch.tensor([indexed_tokens_name])\n",
        "       # tokens_tensor_caption  = torch.tensor([indexed_tokens_caption])\n",
        "\n",
        "        tokens_tensor_name    = tokens_tensor_name[0,:512] #to prevent tokens sequence longer than 512 tokens\n",
        "      #  tokens_tensor_caption = tokens_tensor_caption[0,:412] #to prevent tokens sequence longer than 512 tokens\n",
        "\n",
        "        #return  torch.cat((tokens_tensor_name,tokens_tensor_caption),0),self.labels[:,idx]\n",
        "        return  tokens_tensor_name,self.labels[:,idx]\n",
        "\n",
        "def generate_batch(data_batch):\n",
        "  tokens_batch = [item[0] for item in data_batch]\n",
        "  labels_batch = [item[1] for item in data_batch]\n",
        "  tokens_batch = pad_sequence(tokens_batch,batch_first=True, padding_value=1)\n",
        "  labels_batch = pad_sequence(labels_batch,batch_first=True, padding_value=0) #just to have tensor instead of list\n",
        "  \n",
        "  return tokens_batch, labels_batch\n",
        "\n",
        "trainSet= TextDataset()\n",
        "trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=16,shuffle=True, collate_fn=generate_batch)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTyHouu2pNRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de47e38e-066f-448a-9412-c1074a518919"
      },
      "source": [
        "class CustomModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "\n",
        "        \n",
        "        self.encoder   =  BertModel.from_pretrained('cl-tohoku/bert-base-japanese-v2')\n",
        "        for param in self.encoder.parameters(): \n",
        "                param.requires_grad = False\n",
        "        self.fc1 = torch.nn.Linear(768, 450)\n",
        "        self.fc2 = torch.nn.Linear(450, 200)\n",
        "        self.fc3 = torch.nn.Linear(200, 19)\n",
        "\n",
        "\n",
        "    def forward(self, tokens_tensor):\n",
        "        text_features  = self.encoder.forward(input_ids=tokens_tensor,return_dict=True)\n",
        "        text_features  = text_features['pooler_output'].squeeze(0)\n",
        "        text_features = F.relu(self.fc1(text_features))\n",
        "        text_features = F.relu(self.fc2(text_features))\n",
        "        logits = self.fc3(text_features)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def relaxation(self,type_relax):\n",
        "        if type_relax==\"soft\":\n",
        "            for name,param in self.named_parameters():\n",
        "                if name.startswith('encoder.encoder.layer.11') or name.startswith('encoder.pooler.dense'):\n",
        "                    param.requires_grad = True\n",
        "        elif type_relax==\"hard\":\n",
        "            for param in self.encoder.parameters(): \n",
        "                param.requires_grad = True\n",
        "    \n",
        "\n",
        "model=CustomModel()\n",
        "model.relaxation('soft')\n",
        "model.to(device)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomModel(\n",
              "  (encoder): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32768, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (fc1): Linear(in_features=768, out_features=450, bias=True)\n",
              "  (fc2): Linear(in_features=450, out_features=200, bias=True)\n",
              "  (fc3): Linear(in_features=200, out_features=19, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4El24kbxP7D3"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHOITL3-P8hx"
      },
      "source": [
        "nbr_labels_positive = torch.tensor([25673,71831,34014,33338,2383,8303,21697,28814,8353,12597,25017,10378,24582,10355,23583,12911,3325,51751,14534]) #number of labels\n",
        "nbr_labels_negative = nbr_labels_positive.sum()*torch.ones(19)-nbr_labels_positive\n",
        "coeffs = nbr_labels_negative/nbr_labels_positive    #coefficients for each label\n",
        "coeffs = coeffs.to(device)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mLlR45aP__K"
      },
      "source": [
        "criterion = torch.nn.BCEWithLogitsLoss()#pos_weight=coeffs)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.7)\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainLoader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        if batch_idx%100==0:\n",
        "            print('{:.0f}%|Train Loss: {:.5f} '.format(100*batch_idx/(len(trainLoader)+1),train_loss/(batch_idx+1)))\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "tnbZj7cfSJQ0",
        "outputId": "2060b235-4a0f-4910-a340-99e163ef4c4b"
      },
      "source": [
        "# training loop\n",
        "for epoch in range(100):\n",
        "    train(epoch)\n",
        "    scheduler.step()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            "0%|Train Loss: 0.69033 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-cfd2c4d7a85d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-95e43717f927>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2Dtdj7_QERa"
      },
      "source": [
        "#Save weights\n",
        "model_file = \"/content/drive/MyDrive/data_rakuten/textmodelFinetune.pth\"\n",
        "torch.save(model.state_dict(), model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMMQBTLEQIey"
      },
      "source": [
        "#Load weights\n",
        "model_file = \"/content/drive/MyDrive/data_rakuten/textmodelFinetune.pth\"\n",
        "state_dict = torch.load(model_file)\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_gpsdBZQQSy"
      },
      "source": [
        "## Generate csv file for submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTFJssujQTmi"
      },
      "source": [
        "class TestDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self,):\n",
        "\n",
        "        self.features = XTest[\"item_caption\"]\n",
        "        \n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.features.shape[1]\n",
        "\n",
        "\n",
        "    #all this processing needs to be done here because the output of __getitem__ needs to have a fixed size to use a BS>1\n",
        "    def __getitem__(self, idx):\n",
        " \n",
        "        return  self.features[:,idx]\n",
        "\n",
        "testSet= TestDataset()\n",
        "testLoader = torch.utils.data.DataLoader(testSet, batch_size=1,shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvAZ9dfXQVVg"
      },
      "source": [
        "inv_dico_labels={ 0: \"Beige\",1:\"Black\",2:\"Blue\",3:\"Brown\",4:\"Burgundy\",5:\"Gold\",6:\"Green\",7:\"Grey\",\n",
        "                 8:\"Khaki\",9:\"Multiple Colors\",10:\"Navy\",11:\"Orange\",12:\"Pink\",\n",
        "                 13:\"Purple\",14:\"Red\",15:\"Silver\",16:\"Transparent\",17:\"White\",18:\"Yellow\"}\n",
        "\n",
        "model.eval()\n",
        "\n",
        "#Write prediction in the submission.csv file\n",
        "\n",
        "with open('/content/drive/MyDrive/data_rakuten/submission.csv', 'w') as csvfile:\n",
        "    spamwriter = csv.writer(csvfile, delimiter=',')\n",
        "    spamwriter.writerow([',color_tags,'])\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, inputs in enumerate(testLoader):\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            prediction=[]\n",
        "            for indice,logits in enumerate(outputs.squeeze(0)):\n",
        "                if logits>0: #put the tag if the proba is greater than 0.5\n",
        "                    prediction.append(inv_dico_labels[indice]) \n",
        "            \n",
        "            if len(prediction)>1:\n",
        "                spamwriter.writerow(['{},\"{}\"'.format(batch_idx,prediction)])\n",
        "            else:\n",
        "                spamwriter.writerow(['{},{}'.format(batch_idx,prediction)])\n",
        "            if batch_idx>300:\n",
        "              break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}