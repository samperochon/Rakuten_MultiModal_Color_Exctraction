{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_finetuning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPJomRtyMN4DX6uEWYNn5Sp"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqXc6NYwQno0"
      },
      "source": [
        "# Preliminaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjBsjOepupvb"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaccpgM3CgFY"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import os\n",
        "import ast\n",
        "\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVeoVKGxusJC"
      },
      "source": [
        "## Device configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5tZJVdBCnzC",
        "outputId": "c917c94d-1e8e-4152-d0cb-a8b35b4d7dba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bPFJcIxuvd-"
      },
      "source": [
        "## Conect to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCljQXoCo3WU",
        "outputId": "ddcf972e-0321-4250-f926-78d629eabd74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jxHlncVo5K4"
      },
      "source": [
        "source_folder = '/content/drive/MyDrive/data_rakuten' #source folder of csv files"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4KQymK3uzyh"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHDmUq-0pLRw"
      },
      "source": [
        "#Load data\n",
        "\n",
        "XTrain = pd.read_csv(os.path.join(source_folder,'X_train_12tkObq.csv'), index_col=0)\n",
        "XTest = pd.read_csv(os.path.join(source_folder,'X_test_gDTIJPh.csv'), index_col=0)\n",
        "\n",
        "Ytrain_label = torch.load('/content/drive/MyDrive/data_rakuten/Ytrain_label.pt')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yrXk0-Ou3nP"
      },
      "source": [
        "## Create dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoRd02tGpQOH"
      },
      "source": [
        "class TextDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "      #Load pre-computed tensors\n",
        "      self.text = XTrain['item_name']\n",
        "      self.tokenizer = BertTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-v2')\n",
        "      self.labels = Ytrain_label\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokenized_text = self.tokenizer.tokenize(self.text[idx])\n",
        "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "        tokens_tensor  = torch.tensor([indexed_tokens])\n",
        "        tokens_tensor = tokens_tensor[0,:512] #to prevent tokens sequence longer than 512 tokens\n",
        "\n",
        "        return  tokens_tensor,self.labels[:,idx]\n",
        "\n",
        "def generate_batch(data_batch):\n",
        "  tokens_batch = [item[0] for item in data_batch]\n",
        "  labels_batch = [item[1] for item in data_batch]\n",
        "  tokens_batch = pad_sequence(tokens_batch,batch_first=True, padding_value=1)\n",
        "  labels_batch = pad_sequence(labels_batch,batch_first=True, padding_value=0) #just to have tensor instead of list\n",
        "  \n",
        "  return tokens_batch, labels_batch\n",
        "\n",
        "trainSet= TextDataset()\n",
        "trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=64,shuffle=True, collate_fn=generate_batch)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTyHouu2pNRB",
        "outputId": "ef541dab-c7e5-4c8f-855f-3cab616a8cb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "class CustomModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "\n",
        "        \n",
        "        self.encoder   =  BertModel.from_pretrained('cl-tohoku/bert-base-japanese-v2')\n",
        "        for param in self.encoder.parameters(): \n",
        "                param.requires_grad = False\n",
        "        self.fc1 = torch.nn.Linear(768, 300)\n",
        "        self.fc2 = torch.nn.Linear(300, 19)\n",
        "\n",
        "\n",
        "    def forward(self, tokens_tensor):\n",
        "        text_features  = self.encoder.forward(input_ids=tokens_tensor,return_dict=True)\n",
        "        text_features  = text_features['pooler_output'].squeeze(0)\n",
        "        text_features = F.relu(self.fc1(text_features))\n",
        "        logits = self.fc2(text_features)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def relaxation(self,type_relax):\n",
        "        if type_relax==\"soft\":\n",
        "            for name,param in self.named_parameters():\n",
        "                if name.startswith('encoder.encoder.layer.11') or name.startswith('encoder.pooler.dense'):\n",
        "                    param.requires_grad = True\n",
        "        elif type_relax==\"hard\":\n",
        "            for param in self.encoder.parameters(): \n",
        "                param.requires_grad = True\n",
        "    \n",
        "\n",
        "model=CustomModel()\n",
        "model.relaxation('soft')\n",
        "model.to(device)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomModel(\n",
              "  (encoder): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32768, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (fc1): Linear(in_features=768, out_features=300, bias=True)\n",
              "  (fc2): Linear(in_features=300, out_features=19, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ByTJG2WEEL_",
        "outputId": "e69ce5d2-aae1-4619-8146-83567ce1f83e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for name,param in model.named_parameters():\n",
        "    print(param.requires_grad)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4El24kbxP7D3"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHOITL3-P8hx"
      },
      "source": [
        "nbr_labels_positive = torch.tensor([25673,71831,34014,33338,2383,8303,21697,28814,8353,12597,25017,10378,24582,10355,23583,12911,3325,51751,14534]) #number of labels\n",
        "nbr_labels_negative = nbr_labels_positive.sum()*torch.ones(19)-nbr_labels_positive\n",
        "coeffs = nbr_labels_negative/nbr_labels_positive    #coefficients for each label\n",
        "coeffs = coeffs.to(device)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mLlR45aP__K"
      },
      "source": [
        "criterion = torch.nn.BCEWithLogitsLoss()#pos_weight=coeffs)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.15)\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainLoader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        if batch_idx%100==0:\n",
        "            print('{:.0f}%|Train Loss: {:.5f} '.format(100*batch_idx/(len(trainLoader)+1),train_loss/(batch_idx+1)))\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQK7HVrYq0xs",
        "outputId": "32367167-4685-4ba6-abe0-60e52d2e4ded",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# training loop\n",
        "for epoch in range(1):\n",
        "    train(epoch)\n",
        "    scheduler.step()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            "0%|Train Loss: 0.69626 \n",
            "3%|Train Loss: 0.32320 \n",
            "6%|Train Loss: 0.31617 \n",
            "9%|Train Loss: 0.31428 \n",
            "12%|Train Loss: 0.31039 \n",
            "15%|Train Loss: 0.30911 \n",
            "18%|Train Loss: 0.30773 \n",
            "21%|Train Loss: 0.30692 \n",
            "24%|Train Loss: 0.30629 \n",
            "27%|Train Loss: 0.30567 \n",
            "30%|Train Loss: 0.30505 \n",
            "33%|Train Loss: 0.30481 \n",
            "36%|Train Loss: 0.30429 \n",
            "39%|Train Loss: 0.30391 \n",
            "42%|Train Loss: 0.30371 \n",
            "45%|Train Loss: 0.30349 \n",
            "48%|Train Loss: 0.30316 \n",
            "51%|Train Loss: 0.30283 \n",
            "54%|Train Loss: 0.30251 \n",
            "57%|Train Loss: 0.30219 \n",
            "60%|Train Loss: 0.30214 \n",
            "63%|Train Loss: 0.30171 \n",
            "66%|Train Loss: 0.30149 \n",
            "69%|Train Loss: 0.30136 \n",
            "72%|Train Loss: 0.30115 \n",
            "75%|Train Loss: 0.30081 \n",
            "78%|Train Loss: 0.30058 \n",
            "81%|Train Loss: 0.30035 \n",
            "84%|Train Loss: 0.30010 \n",
            "87%|Train Loss: 0.29996 \n",
            "90%|Train Loss: 0.29978 \n",
            "93%|Train Loss: 0.29964 \n",
            "97%|Train Loss: 0.29947 \n",
            "100%|Train Loss: 0.29944 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2Dtdj7_QERa"
      },
      "source": [
        "#Save weights\n",
        "model_file = \"/content/drive/MyDrive/data_rakuten/textmodelFinetune.pth\"\n",
        "torch.save(model.state_dict(), model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMMQBTLEQIey"
      },
      "source": [
        "#Load weights\n",
        "model_file = \"/content/drive/MyDrive/data_rakuten/textmodelFinetune.pth\"\n",
        "state_dict = torch.load(model_file)\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_gpsdBZQQSy"
      },
      "source": [
        "## Generate csv file for submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTFJssujQTmi"
      },
      "source": [
        "class TestDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self,):\n",
        "\n",
        "        self.features = XTest[\"item_caption\"]\n",
        "        \n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.features.shape[1]\n",
        "\n",
        "\n",
        "    #all this processing needs to be done here because the output of __getitem__ needs to have a fixed size to use a BS>1\n",
        "    def __getitem__(self, idx):\n",
        " \n",
        "        return  self.features[:,idx]\n",
        "\n",
        "testSet= TestDataset()\n",
        "testLoader = torch.utils.data.DataLoader(testSet, batch_size=1,shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvAZ9dfXQVVg"
      },
      "source": [
        "inv_dico_labels={ 0: \"Beige\",1:\"Black\",2:\"Blue\",3:\"Brown\",4:\"Burgundy\",5:\"Gold\",6:\"Green\",7:\"Grey\",\n",
        "                 8:\"Khaki\",9:\"Multiple Colors\",10:\"Navy\",11:\"Orange\",12:\"Pink\",\n",
        "                 13:\"Purple\",14:\"Red\",15:\"Silver\",16:\"Transparent\",17:\"White\",18:\"Yellow\"}\n",
        "\n",
        "model.eval()\n",
        "\n",
        "#Write prediction in the submission.csv file\n",
        "\n",
        "with open('/content/drive/MyDrive/data_rakuten/submission.csv', 'w') as csvfile:\n",
        "    spamwriter = csv.writer(csvfile, delimiter=',')\n",
        "    spamwriter.writerow([',color_tags,'])\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, inputs in enumerate(testLoader):\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            prediction=[]\n",
        "            for indice,logits in enumerate(outputs.squeeze(0)):\n",
        "                if logits>0: #put the tag if the proba is greater than 0.5\n",
        "                    prediction.append(inv_dico_labels[indice]) \n",
        "            \n",
        "            if len(prediction)>1:\n",
        "                spamwriter.writerow(['{},\"{}\"'.format(batch_idx,prediction)])\n",
        "            else:\n",
        "                spamwriter.writerow(['{},{}'.format(batch_idx,prediction)])\n",
        "            if batch_idx>300:\n",
        "              break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}