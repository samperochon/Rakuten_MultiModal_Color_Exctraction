{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "precompute_textual_feature.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivmVyMwDPQBC"
      },
      "source": [
        "**As we have to deal with a multimodal classification task, DataLoader from `torchtext.data` cannot be used. This result in a prohibiting computation time if we compute the features on the fly.** \\\n",
        "**Furthemore, the BERT base model is a huge model and already very accurate so we will not fine-tune it. We want to use it as a feature extactor only.** \\\n",
        "<font color='red'> **==> We will precompute the textual features and save them in `torch.tensors`.** </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gIYclmObog7"
      },
      "source": [
        "# Preliminaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJtIENB0cF5J"
      },
      "source": [
        "## Install and import libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wuq8q4ZJ8Sz"
      },
      "source": [
        "!pip install transformers==3.5.1  #to use repo cl-tohoku/bert-japanese\n",
        "!pip install sentencepiece #to deal with Japanese language\n",
        "!pip install fugashi #to deal with Japanese language\n",
        "!pip install ipadic  #to deal with Japanese language\n",
        "\n",
        "import torch\n",
        "import os\n",
        "import fugashi \n",
        "import ast\n",
        "import csv\n",
        "import pandas as pd\n",
        "from transformers.tokenization_bert_japanese import BertJapaneseTokenizer\n",
        "from transformers import BertModel\n",
        "from torchtext.data import Field, TabularDataset, BucketIterator, Iterator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uebs-Yy6b9-n"
      },
      "source": [
        "## Set computation engine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4gY0v3cbwM7"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVRu7l0OXuFf"
      },
      "source": [
        "## Connect to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS6mqLI8XwpC"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro8lczLNXYti"
      },
      "source": [
        "#Load text data and compute features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rep3Xz8oOKE5"
      },
      "source": [
        "source_folder = '/content/drive/MyDrive/data_rakuten' #source folder of csv files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIwh5okgSbxZ"
      },
      "source": [
        "#Tokenizer\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese\")\n",
        "\n",
        "#BERT\n",
        "encoder = BertModel.from_pretrained('cl-tohoku/bert-base-japanese')\n",
        "for param in encoder.parameters():  #Freeze the weights of BERT because we want to use it only for sentence embedding\n",
        "    param.requires_grad = False\n",
        "\n",
        "encoder.eval()\n",
        "encoder.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzJrsJnY-siE"
      },
      "source": [
        "#Load data\n",
        "\n",
        "XTrain = pd.read_csv(os.path.join(source_folder,'X_train_12tkObq.csv'), index_col=0)\n",
        "XTest = pd.read_csv(os.path.join(source_folder,'X_test_gDTIJPh.csv'), index_col=0)\n",
        "\n",
        "YTrain = pd.read_csv(os.path.join(source_folder,'y_train_Q9n2dCu.csv'), index_col=0)\n",
        "YTrain['color_tags'] = YTrain['color_tags'].apply(lambda x: ast.literal_eval(x)) #to change str to list labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsQsac_nB4rP"
      },
      "source": [
        "def compute_feature(text):\n",
        "    tokenized_text = tokenizer.tokenize(text)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    tokens_tensor  = torch.tensor([indexed_tokens]).to(device)\n",
        "    tokens_tensor=tokens_tensor[:,:512] #to prevent tokens sequence longer than 512 tokens\n",
        "    text_features  = encoder.forward(input_ids=tokens_tensor,return_dict=True)\n",
        "    pooler_output  = text_features['pooler_output'].squeeze(0)\n",
        "\n",
        "    return  pooler_output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z6PtXvZJnVA"
      },
      "source": [
        "Xtrain_item_caption=torch.zeros([768,len(XTrain)])   # a big guy :p\n",
        "\n",
        "for idx,item_caption in enumerate(XTrain[\"item_caption\"]):\n",
        "    Xtrain_item_caption[:,idx] = compute_feature(\"item_caption\")\n",
        "    if idx%1000==0:\n",
        "      print(idx)\n",
        "\n",
        "torch.save(Xtrain_item_caption,'/content/drive/MyDrive/data_rakuten/Xtrain_item_caption.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AeAqhsE9EB1"
      },
      "source": [
        "Xtrain_item_name=torch.zeros([768,len(XTrain)])   # another big guy :p\n",
        "\n",
        "for idx,item_name in enumerate(XTrain[\"item_name\"]):\n",
        "    Xtrain_item_name[:,idx] = compute_feature(\"item_name\")\n",
        "    if idx%1000==0:\n",
        "      print(idx)\n",
        "\n",
        "torch.save(Xtrain_item_name,'/content/drive/MyDrive/data_rakuten/Xtrain_item_name.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC_wVq4FLjK7"
      },
      "source": [
        "Xtest_item_caption=torch.zeros([768,len(XTest)])   # another big guy :p\n",
        "\n",
        "for idx,item_caption in enumerate(XTest[\"item_caption\"]):\n",
        "    Xtest_item_caption[:,idx] = compute_feature(\"item_caption\")\n",
        "    if idx%1000==0:\n",
        "      print(idx)\n",
        "\n",
        "torch.save(Xtest_item_caption,'/content/drive/MyDrive/data_rakuten/Xtest_item_caption.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKvLzkD6Ldtk"
      },
      "source": [
        "Xtest_item_name=torch.zeros([768,len(XTest)])   # another big guy :p\n",
        "\n",
        "for idx,item_name in enumerate(XTest[\"item_name\"]):\n",
        "    Xtest_item_name[:,idx] = compute_feature(\"item_name\")\n",
        "    if idx%1000==0:\n",
        "      print(idx)\n",
        "\n",
        "torch.save(Xtest_item_name,'/content/drive/MyDrive/data_rakuten/Xtest_item_name.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IDVgTF-Kbph"
      },
      "source": [
        "dico_labels={  \"Beige\": 0,  \"Black\": 1,  \"Blue\": 2,  \"Brown\": 3,  \"Burgundy\": 4,  \"Gold\": 5,  \"Green\": 6,  \n",
        "  \"Grey\": 7,    \"Khaki\": 8,  \"Multiple Colors\": 9,  \"Navy\": 10,  \"Orange\": 11,\n",
        "  \"Pink\": 12,\"Purple\": 13,\"Red\": 14,\"Silver\": 15, \"Transparent\": 16,\"White\": 17,\"Yellow\": 18  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cslP6Z5NKmWA"
      },
      "source": [
        "Ytrain_label=torch.zeros([19,len(YTrain)])   # another big guy :p\n",
        "\n",
        "for idx,str_labels in enumerate(YTrain['color_tags']):\n",
        "    int_labels=[dico_labels[color] for color in str_labels]\n",
        "    tensor_labels=torch.zeros(19)\n",
        "    for label in int_labels:\n",
        "        Ytrain_label[label,idx]=1\n",
        "\n",
        "    if idx%1000==0:\n",
        "      print(idx)\n",
        "\n",
        "torch.save(Ytrain_label,'/content/drive/MyDrive/data_rakuten/Ytrain_label.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}