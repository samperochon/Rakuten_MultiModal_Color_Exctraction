{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Approach1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gIYclmObog7"
      },
      "source": [
        "# Preliminaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJtIENB0cF5J"
      },
      "source": [
        "## Install and import libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NdM4ALqcIFH"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import ast\n",
        "import csv\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uebs-Yy6b9-n"
      },
      "source": [
        "## Set computation engine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4gY0v3cbwM7",
        "outputId": "7ec5b5ca-98a2-49f0-ccd3-de15c3032f16"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVRu7l0OXuFf"
      },
      "source": [
        "## Connect to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS6mqLI8XwpC",
        "outputId": "68a61e6e-cf36-44de-a39b-8bcb6a29877e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro8lczLNXYti"
      },
      "source": [
        "#Load precomputed text features "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxl04kVRUGNe"
      },
      "source": [
        "ProportionTrainVal=0.7\n",
        "\n",
        "Xtrain_item_name = torch.load('/content/drive/MyDrive/data_rakuten/Xtrain_item_name.pt')\n",
        "Xtrain_item_caption = torch.load('/content/drive/MyDrive/data_rakuten/Xtrain_item_caption.pt')\n",
        "Ytrain_label = torch.load('/content/drive/MyDrive/data_rakuten/Ytrain_label.pt')\n",
        "X_features=torch.cat((Xtrain_item_name,Xtrain_item_caption),0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDVb8m5LuMMw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3266b0c7-f6f0-4700-e8ea-ba0b2b9e3f17"
      },
      "source": [
        "X_features.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1536, 212120])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdfYv3CXRrxe"
      },
      "source": [
        "class TextDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self,features,labels):\n",
        "      #Load pre-computed tensors\n",
        "      self.features=features\n",
        "      self.labels=labels\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.features.shape[1]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        return  self.features[:,idx],self.labels[:,idx]\n",
        "\n",
        "trainSet= TextDataset(X_features[:,:int(X_features.shape[1]*ProportionTrainVal)],Ytrain_label[:,:int(X_features.shape[1]*ProportionTrainVal)])\n",
        "trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=64,shuffle=True, num_workers=2)\n",
        "\n",
        "valSet= TextDataset(X_features[:,int(X_features.shape[1]*ProportionTrainVal):],Ytrain_label[:,int(X_features.shape[1]*ProportionTrainVal):])\n",
        "valLoader = torch.utils.data.DataLoader(valSet, batch_size=64,shuffle=False, num_workers=2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG6QG5U2ZIRA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c80969b-877a-46a3-d260-e68df226d1fe"
      },
      "source": [
        "len(valSet)+len(trainSet)==X_features.shape[1]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqE-Wfpr3IJX"
      },
      "source": [
        "# Our prediction model : SVM approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUhAfw_o3TfZ",
        "outputId": "98b4ab2d-7b93-483b-8bb4-4cddd77ee5c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn import svm\n",
        "import numpy as np\n",
        "X = X_features.permute(1,0)[:10000,:] #(n_samples, n_features)\n",
        "Y = Ytrain_label[1,:][:10000]  #n_samples\n",
        "clf = svm.SVC()\n",
        "clf.fit(X, Y)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFzwz79Q5WVg",
        "outputId": "57940591-de00-4a00-ca92-a3a81a306c16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_val = X_features.permute(1,0)[10000:12000,:] #(n_samples, n_features)\n",
        "Y_val = Ytrain_label[1,:][10000:12000]  #n_samples\n",
        "predictions=clf.predict(X_val)\n",
        "accuracy=(np.array(predictions)==np.array(Y_val)).mean()\n",
        "print(accuracy)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCIR6zXLYAHw"
      },
      "source": [
        "# Our prediction model : Neural approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOuvOAZBtbzV"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwUARX4WYBqh",
        "outputId": "1fa9675e-347d-45e6-edef-419367b9bec2"
      },
      "source": [
        "class CustomModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "\n",
        "        #self.dropout = torch.nn.Dropout(0.1)\n",
        "        self.fc1 = torch.nn.Linear(1536, 256)\n",
        "        self.fc2 = torch.nn.Linear(256, 128)\n",
        "        self.fc3 = torch.nn.Linear(128, 19)\n",
        "\n",
        "\n",
        "    def forward(self, text_features):\n",
        "        text_features = F.relu(self.fc1(text_features))\n",
        "        text_features = F.relu(self.fc2(text_features))\n",
        "        #text_features = self.dropout(text_features)\n",
        "        logits = self.fc3(text_features)\n",
        "\n",
        "        return logits\n",
        "\n",
        "model=CustomModel()\n",
        "model.to(device)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomModel(\n",
              "  (fc1): Linear(in_features=1536, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (fc3): Linear(in_features=128, out_features=19, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_W_qC1-tgBz"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zktP0oT9HQxM"
      },
      "source": [
        "nbr_labels_positive = torch.tensor([25673,71831,34014,33338,2383,8303,21697,28814,8353,12597,25017,10378,24582,10355,23583,12911,3325,51751,14534]) #number of labels\n",
        "nbr_labels_negative = nbr_labels_positive.sum()*torch.ones(19)-nbr_labels_positive\n",
        "coeffs = nbr_labels_negative/nbr_labels_positive    #coefficients for each label\n",
        "coeffs = coeffs.to(device)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0Oh59DVQoDN"
      },
      "source": [
        "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=coeffs)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.15)\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainLoader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        if batch_idx%1000==0:\n",
        "            print('{:.0f}%|Train Loss: {:.5f} '.format(100*batch_idx/(len(trainLoader)+1),train_loss/(batch_idx+1)))\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92WP5Y58q-yw"
      },
      "source": [
        "# training loop\n",
        "for epoch in range(30):\n",
        "    train(epoch)\n",
        "    scheduler.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6T0LPrQ2cL_"
      },
      "source": [
        "#Save weights\n",
        "model_file = \"/content/drive/MyDrive/data_rakuten/textmodel.pth\"\n",
        "torch.save(model.state_dict(), model_file)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sujzzGUM6-wB",
        "outputId": "7c7c2255-a7ab-4c2c-e019-06b43b405d91"
      },
      "source": [
        "#Load weights\n",
        "model_file = \"/content/drive/MyDrive/data_rakuten/textmodel.pth\"\n",
        "state_dict = torch.load(model_file)\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Bp40W-rIl1s"
      },
      "source": [
        "# Generate csv file for submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z77idHmEJiDK"
      },
      "source": [
        "class TestDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self,):\n",
        "\n",
        "        self.Xtest_item_name = torch.load('/content/drive/MyDrive/data_rakuten/Xtest_item_name.pt')\n",
        "        self.Xtest_item_caption = torch.load('/content/drive/MyDrive/data_rakuten/Xtest_item_caption.pt')\n",
        "        \n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.Xtest_item_name.shape[1]\n",
        "\n",
        "\n",
        "    #all this processing needs to be done here because the output of __getitem__ needs to have a fixed size to use a BS>1\n",
        "    def __getitem__(self, idx):\n",
        " \n",
        "        return  torch.cat((self.Xtest_item_name[:,idx] ,self.Xtest_item_caption[:,idx]),0)\n",
        "\n",
        "testSet= TestDataset()\n",
        "testLoader = torch.utils.data.DataLoader(testSet, batch_size=1,shuffle=False, num_workers=2)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU3vG7ZRIoXt"
      },
      "source": [
        "inv_dico_labels={ 0: \"Beige\",1:\"Black\",2:\"Blue\",3:\"Brown\",4:\"Burgundy\",5:\"Gold\",6:\"Green\",7:\"Grey\",\n",
        "                 8:\"Khaki\",9:\"Multiple Colors\",10:\"Navy\",11:\"Orange\",12:\"Pink\",\n",
        "                 13:\"Purple\",14:\"Red\",15:\"Silver\",16:\"Transparent\",17:\"White\",18:\"Yellow\"}\n",
        "\n",
        "model.eval()\n",
        "\n",
        "#Write prediction in the submission.csv file\n",
        "\n",
        "with open('/content/drive/MyDrive/data_rakuten/submission.csv', 'w') as csvfile:\n",
        "    spamwriter = csv.writer(csvfile, delimiter=',')\n",
        "    spamwriter.writerow([',color_tags,'])\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, inputs in enumerate(testLoader):\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            prediction=[]\n",
        "            for indice,logits in enumerate(outputs.squeeze(0)):\n",
        "                if logits>0: #put the tag if the proba is greater than 0.5\n",
        "                    prediction.append(inv_dico_labels[indice]) \n",
        "            \n",
        "            if len(prediction)>1:\n",
        "                spamwriter.writerow(['{},\"{}\"'.format(batch_idx,prediction)])\n",
        "            else:\n",
        "                spamwriter.writerow(['{},{}'.format(batch_idx,prediction)])\n",
        "            if batch_idx>300:\n",
        "              break"
      ],
      "execution_count": 48,
      "outputs": []
    }
  ]
}